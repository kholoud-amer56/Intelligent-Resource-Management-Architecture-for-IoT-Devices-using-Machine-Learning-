# app_resource_manager_commented.py
# =========================================
# Adaptive Resource Manager â€” Professional Decision Engine
# =========================================

# =========================================
# IMPORT LIBRARIES
# =========================================
import streamlit as st       # ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©
import pandas as pd          # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø´ÙƒÙ„ DataFrame
import numpy as np           # Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ© ÙˆØ§Ù„Ù…ØµÙÙˆÙØ§Øª
import joblib                # Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø­ÙÙˆØ¸ ÙˆØ§Ù„Ù€ scaler
import json                  # Ù„Ù‚Ø±Ø§Ø¡Ø© feature columns
import os                    # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª
from datetime import datetime # Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆÙ‚Øª Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns        # Ù„Ø±Ø³Ù… heatmaps ÙˆVisualization

# =========================================
# STREAMLIT CONFIG
# =========================================
# set_page_config ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø£ÙˆÙ„ Ø£Ù…Ø± ÙÙŠ Ø§Ù„Ù€ Streamlit
st.set_page_config(
    page_title="Adaptive Resource Manager",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =========================================
# CONFIG FILES
# =========================================
MODEL_PATH = "best_logistic_regression_model.pkl"  # Ù…Ù„Ù Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠÙƒ
SCALER_PATH = "minmax_scaler.pkl"                  # Ù…Ù„Ù MinMaxScaler
AUDIT_LOG_PATH = "resource_actions_log.csv"       # Ù…Ù„Ù ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª
TEST_DATA_PATH = "processed_dataset_fixed.xlsx"   # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©
FEATURES_PATH = "feature_columns.json"            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù€ Features Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„

# =========================================
# LOAD MODEL, SCALER, FEATURES
# =========================================
# Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
try:
    model = joblib.load(MODEL_PATH)
except Exception as e:
    st.error(f"Error loading model: {e}")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ scaler (MinMaxScaler)
try:
    scaler = joblib.load(SCALER_PATH)
except Exception as e:
    st.error(f"Error loading scaler: {e}")

# ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù€ Features (Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©) Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
try:
    with open(FEATURES_PATH, "r") as f:
        FEATURES = json.load(f)
except Exception as e:
    st.error(f"Error loading feature columns: {e}")

# =========================================
# UTILITY FUNCTIONS
# =========================================
def preprocess_row(row: dict):
    """
    ØªØ­ÙˆÙŠÙ„ Dictionary Ø¥Ù„Ù‰ DataFrame ÙˆØ­Ø´Ùˆ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©.
    row: {'CPU_Usage': 0.5, ...}
    """
    df = pd.DataFrame([row], columns=FEATURES)
    df = df.fillna(0)  # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø£ÙŠ NaN Ø¨Ù€ 0
    return df

def decide_action_from_probs(prob_dict, thresholds):
    """
    ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ (pause/adjust/offload) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª ÙˆØ§Ù„Ù€ thresholds.
    Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: offload > adjust > pause
    """
    if prob_dict.get("offload",0) >= thresholds["offload"]:
        return "offload", prob_dict["offload"], "prob_offload>=threshold"
    if prob_dict.get("adjust",0) >= thresholds["adjust"]:
        return "adjust", prob_dict["adjust"], "prob_adjust>=threshold"
    if prob_dict.get("pause",0) >= thresholds["pause"]:
        return "pause", prob_dict["pause"], "prob_pause>=threshold"
    # fallback: Ø£Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„ Ø¥Ø°Ø§ Ù„Ù… ÙŠØµÙ„ Ø£ÙŠ Ø§Ø­ØªÙ…Ø§Ù„ Ù„Ù„Ù€ threshold
    pred = max(prob_dict, key=prob_dict.get)
    return pred, prob_dict[pred], "fallback_highest_prob"

def log_action(record: dict):
    """
    ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø§Ø± ÙÙŠ Ù…Ù„Ù CSV.
    record: {'timestamp':..., 'device_id':..., 'input':..., 'decision':..., ...}
    """
    df = pd.DataFrame([record])
    try:
        if os.path.exists(AUDIT_LOG_PATH):
            # Append without header
            df.to_csv(AUDIT_LOG_PATH, mode='a', header=False, index=False)
        else:
            df.to_csv(AUDIT_LOG_PATH, index=False)
    except Exception as e:
        st.error(f"Error logging action: {e}")

# =========================================
# SIDEBAR CONFIGURATION
# =========================================
st.sidebar.header("Configuration")

# Ø¥Ø¹Ø¯Ø§Ø¯ sliders Ù„Ù„Ù€ thresholds Ù„ÙƒÙ„ Ø¥Ø¬Ø±Ø§Ø¡
th_offload = st.sidebar.slider("Threshold offload", 0.01, 0.99, 0.60, 0.01)
th_adjust = st.sidebar.slider("Threshold adjust", 0.01, 0.99, 0.50, 0.01)
th_pause = st.sidebar.slider("Threshold pause", 0.01, 0.99, 0.70, 0.01)
thresholds = {"offload": th_offload, "adjust": th_adjust, "pause": th_pause}

st.sidebar.markdown("---")
st.sidebar.write("Audit log file:")
st.sidebar.code(AUDIT_LOG_PATH)
st.sidebar.markdown("---")

# =========================================
# PAGE HEADER
# =========================================
st.title("ğŸ”§ Resource Manager â€” Decision Engine")
st.markdown("Use the interface to predict actions (pause/adjust/offload) and log all decisions.")

# =========================================
# TABS FOR DIFFERENT FUNCTIONALITY
# =========================================
tab1, tab2, tab3 = st.tabs(["Single Inference", "Batch Inference", "Monitoring & Reports"])

# -----------------------------------------
# SINGLE INFERENCE TAB
# -----------------------------------------
with tab1:
    st.header("Single Inference / Decision")
    col1, col2 = st.columns(2)

    # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±Ø¯ÙŠØ© Ù„ÙƒÙ„ Feature
    with col1:
        CPU_Usage = st.number_input("CPU_Usage", 0.0, 1.0, 0.5, format="%.4f")
        Bandwidth_Usage = st.number_input("Bandwidth_Usage", 0.0, 1.0, 0.5, format="%.4f")
        Energy_Consumption = st.number_input("Energy_Consumption", 0.0, 1.0, 0.5, format="%.4f")
    with col2:
        LSTM_Predicted_log = st.number_input("LSTM_Predicted_log", -10.0, 10.0, 0.0, format="%.6f")
        timestamp_numeric = st.number_input("timestamp_numeric", 0.0, 1.0, 0.5, format="%.6f")
        LSTM_timestamp = st.number_input("LSTM_timestamp", 0.0, 1.0, 0.5, format="%.6f")

    device_id = st.text_input("Device ID (optional)", value="device_001")

    if st.button("ğŸ” Predict & Decide"):
        # Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
        sample = {
            "CPU_Usage": CPU_Usage,
            "Bandwidth_Usage": Bandwidth_Usage,
            "Energy_Consumption": Energy_Consumption,
            "LSTM_Predicted_log": LSTM_Predicted_log,
            "timestamp_numeric": timestamp_numeric,
            "LSTM_timestamp": LSTM_timestamp
        }
        df_sample = preprocess_row(sample)

        # ØªØ·Ø¨ÙŠÙ‚ Min-Max Scaling Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
        X_scaled = scaler.transform(df_sample)

        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Class
        probs = model.predict_proba(X_scaled)[0]
        classes = model.classes_
        prob_dict = dict(zip(classes, probs))

        # Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ thresholds
        action, conf, reason = decide_action_from_probs(prob_dict, thresholds)

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ù€ UI
        st.subheader("Result")
        st.write("Model prediction:", classes[np.argmax(probs)])
        st.write("Decision (engine):", action)
        st.write("Confidence:", round(conf, 4))
        st.write("Reason:", reason)
        st.json(prob_dict)

        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø§Ø± ÙÙŠ Ù…Ù„Ù Audit log
        record = {
            "timestamp": datetime.utcnow().isoformat(),
            "device_id": device_id,
            "input": json.dumps(sample),
            "model_pred": classes[np.argmax(probs)],
            "decision": action,
            "confidence": float(conf),
            "reason": reason
        }
        log_action(record)
        st.success("âœ… Decision logged")

# -----------------------------------------
# BATCH INFERENCE TAB
# -----------------------------------------
with tab2:
    st.header("Batch Inference (CSV / Excel)")
    uploaded = st.file_uploader("Upload CSV / XLSX file", type=["csv", "xlsx"])
    if uploaded is not None:
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
            if uploaded.name.endswith(".csv"):
                batch_df = pd.read_csv(uploaded)
            else:
                batch_df = pd.read_excel(uploaded)

            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Features
            missing = set(FEATURES) - set(batch_df.columns)
            if missing:
                st.error(f"Missing columns: {missing}")
            else:
                batch_df = batch_df[FEATURES].fillna(0)

                # ØªØ·Ø¨ÙŠÙ‚ Min-Max Scaling
                X_scaled = scaler.transform(batch_df)

                # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
                probs = model.predict_proba(X_scaled)
                preds = model.predict(X_scaled)
                result_df = batch_df.copy()

                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù„ÙƒÙ„ Class
                for i, cls in enumerate(model.classes_):
                    result_df[f"Prob_{cls}"] = probs[:, i]
                result_df["Model_Pred"] = preds

                # Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„ÙƒÙ„ ØµÙ
                decisions = []
                for idx, row in result_df.iterrows():
                    prob_dict = {cls: row[f"Prob_{cls}"] for cls in model.classes_}
                    action, conf, reason = decide_action_from_probs(prob_dict, thresholds)
                    decisions.append((action, conf, reason))

                result_df["Decision"] = [d[0] for d in decisions]
                result_df["Decision_conf"] = [d[1] for d in decisions]
                result_df["Decision_reason"] = [d[2] for d in decisions]

                st.dataframe(result_df.head(200))
                # ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                csv = result_df.to_csv(index=False).encode('utf-8')
                st.download_button("Download results CSV", data=csv, file_name="batch_predictions_results.csv")

        except Exception as e:
            st.error(f"Error loading file: {e}")

# -----------------------------------------
# MONITORING & REPORTS TAB
# -----------------------------------------
with tab3:
    st.header("Monitoring & Reports")

    # Ø¹Ø±Ø¶ Audit log
    if os.path.exists(AUDIT_LOG_PATH):
        audit_df = pd.read_csv(AUDIT_LOG_PATH)
        st.write("Total logged actions:", len(audit_df))
        st.dataframe(audit_df.tail(100))
    else:
        st.info("No audit log found yet.")

    # Ø¹Ø±Ø¶ Ø§Ù„Ù€ min Ùˆ max Ù„ÙƒÙ„ Feature Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    if TEST_DATA_PATH and os.path.exists(TEST_DATA_PATH):
        test_df = pd.read_excel(TEST_DATA_PATH)
        df_features = test_df[FEATURES].fillna(0)
        st.subheader("Feature-wise min/max (for manual scaling)")
        st.dataframe(pd.DataFrame({
            "min": df_features.min(),
            "max": df_features.max()
        }))

        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ Test Data
        st.subheader("Run Evaluation on Test Data")
        if st.button("Run full evaluation"):
            test_df = test_df.dropna().reset_index(drop=True)
            if not set(FEATURES).issubset(test_df.columns) or "Action_Label" not in test_df.columns:
                st.error("Test file must include features + Action_Label column")
            else:
                X_test = scaler.transform(test_df[FEATURES])
                y_true = test_df["Action_Label"]
                y_pred = model.predict(X_test)
                st.text(classification_report(y_true, y_pred))

                cm = confusion_matrix(y_true, y_pred, labels=model.classes_)
                cm_df = pd.DataFrame(cm, index=[f"Actual:{c}" for c in model.classes_],
                                     columns=[f"Pred:{c}" for c in model.classes_])
                fig, ax = plt.subplots(figsize=(6, 5))
                sns.heatmap(cm_df, annot=True, fmt="d", cmap='Blues', ax=ax)
                st.pyplot(fig)
                st.success("Evaluation complete")

    # Ø¹Ø±Ø¶ Ø§Ù„Ù€ coefficients Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù…ÙˆØ¯ÙŠÙ„ Logistic Regression
    st.subheader("Model coefficients (Logistic Regression)")
    try:
        if hasattr(model, "coef_"):
            coef_df = pd.DataFrame(model.coef_, columns=FEATURES, index=model.classes_)
            st.dataframe(coef_df.T)
        else:
            st.info("Model has no coefficients to show")
    except Exception as e:
        st.error(f"Could not show coefficients: {e}")

st.markdown("---")
st.caption("Adaptive Resource Manager â€” Professional Decision Engine with full logging & monitoring")
